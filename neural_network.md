<!--------------------------------------------------------------------------------- Description -->
# AI : Neural Network
    this is documents of AI : Neural Network

<!--------------------------------------------------------------------------------- Resource -->
<br><br>

# Resource
<!-------------------------- Book -->
Website
```
```
<!-------------------------- Website -->
Website
```
https://datayad.com/
```
<!-------------------------- Video -->
Video
```
Youtube : @saberkolagar : https://www.youtube.com/watch?v=5Y3j3K_KKN4&list=PLbEKSgSYxE7s-aQ8ZpfH8WYEnz4ZKkICO
```

<!--------------------------------------------------------------------------------- Structure -->
<br><br>

# Structure
```
Input
Model
Output
```



<!--------------------------------------------------------------------------------- Subject -->
<br><br>

# Subject
```
Training
Fine-tuning
Attention Mechanism
Transformer
```

<!--------------------------------------------------------------------------------- Type -->
<br><br>

# Type
```
Classification Models
Regression/Prediction Models
Generative Models
Reinforcement Learning Models
Time Series Models
LLM Models
```

<!--------------------------------------------------------------------------------- Model -->
<br><br>

# Model
```
Input Layers
Hidden Layers
Output Layers
Weights
Bias
Activation Functions : Sigmoid

Gradient Descent
Gradient
```

<!--------------------------------------------------------------------------------- Input -->
<br><br>

# Input
```
Type
Lable
Cleaning
Normalization
Tokenize
Limitation
```



<!--------------------------------------------------------------------------------- Training -->
<br><br>

# Training
<!-------------------------- Structure -->
### Structure
```
Feed forward
Error : Loss function | Cost function
Backpropagation
Epoch
Batch
```
<!-------------------------- Type -->
### Type
```
Supervised
Unsupervised
Semi-supervised
Self-supervised
Reinforcement Learning
Online/Incremental
Transfer/Fine-tuning
Few-shot / Zero-shot
Evolutionary methods
```
<!-------------------------- Problem -->
### Problem
```
Vanishing Gradient
```

<!--------------------------------------------------------------------------------- Activation Functions -->
<br><br>

# Activation Functions
<!-------------------------- Structure -->
### Structure
```
Definition | Function | Derivative | Input | Output | Shape | Advantages | Disadvantages | Where it’s used today
```
<!-------------------------- Type -->
### Type
```
Linear | Sigmoid | Tanh | ReLU | ELU | Leaky ReLU | Softmax
```

<!--------------------------------------------------------------------------------- Loss Function -->
<br><br>

# Loss Function
<!-------------------------- Structure -->
### Structure
```
Definition |
```
<!-------------------------- Type -->
### Type
```
Cross-Entropy
```

<!--------------------------------------------------------------------------------- Optimizer -->
<br><br>

# Optimizer
<!-------------------------- Structure -->
### Structure
```
Definition | Function | Advantages | Disadvantages | Where it’s used today
```
<!-------------------------- Type -->
### Type
```
Gradient Descent
Stochastic Gradient Descent
Momentum
```

<!--------------------------------------------------------------------------------- Output -->
<br><br>

# Output
```
Predict
Nois
Output 
Evaluation criteria : Accuracy, Precision, Recall, F1
Feedback & Iteration
Format : Probabilities, Text, Labels, h5, pt, onnx, joblib
```

<!--------------------------------------------------------------------------------- Tools -->
<br><br>

# Tools
<!-------------------------- Python -->
Python
```
numpy
matplotlib
jupyter
```

<!--------------------------------------------------------------------------------- Note -->
<br><br>

# Note
```
Activation Functions Must be differentiable
```

<!--------------------------------------------------------------------------------- Extra -->
<br><br>

# Extra
```
seq2seq
Transformer
Train
Foundation model
Fine-Tuning
Token
Temperature
Matching
Masking
RLHF
Reward model
Medium | Abstraction | Context | Statefulness
Token
```